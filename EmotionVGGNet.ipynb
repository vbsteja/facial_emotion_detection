{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU,Softmax\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "#from config import emotion_config as config\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionVGGNet:\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height,width,depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\tif K.image_data_format == \"channels_first\":\n",
    "\t\t\tinputShape = (depth,height,width)\n",
    "\t\t\tchanDim = 1\n",
    "\t\tmodel = Sequential([\n",
    "\t\t\tConv2D(32,(3,3), padding=\"same\",\n",
    "\t\t\tkernel_initializer=\"he_normal\",input_shape=inputShape),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(axis=chanDim),\n",
    "\t\t\tConv2D(32,(3,3), kernel_initializer=\"he_normal\",\n",
    "\t\t\t\tpadding=\"same\"),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(axis=chanDim),\n",
    "\t\t\tMaxPooling2D(pool_size=(2,2)),\n",
    "\t\t\tDropout(0,25),\n",
    "\t\t\tConv2D(64,(3,3), padding=\"same\",\n",
    "\t\t\tkernel_initializer=\"he_normal\",input_shape=inputShape),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(axis=chanDim),\n",
    "\t\t\tConv2D(64,(3,3), kernel_initializer=\"he_normal\",\n",
    "\t\t\t\tpadding=\"same\"),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(axis=chanDim),\n",
    "\t\t\tMaxPooling2D(pool_size=(2,2)),\n",
    "\t\t\tDropout(0,25),\n",
    "\t\t\tConv2D(64,(3,3), padding=\"same\",\n",
    "\t\t\tkernel_initializer=\"he_normal\",input_shape=inputShape),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(axis=chanDim),\n",
    "\t\t\tConv2D(64,(3,3), kernel_initializer=\"he_normal\",\n",
    "\t\t\t\tpadding=\"same\"),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(axis=chanDim),\n",
    "\t\t\tMaxPooling2D(pool_size=(2,2)),\n",
    "\t\t\tDropout(0,25),\n",
    "\t\t\tFlatten(),\n",
    "\t\t\tDense(64,kernel_initializer=\"he_normal\"),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(),\n",
    "\t\t\tDropout(0.25),\n",
    "\t\t\tDense(64,kernel_initializer=\"he_normal\"),\n",
    "\t\t\tELU(),\n",
    "\t\t\tBatchNormalization(),\n",
    "\t\t\tDropout(0.25),\n",
    "\t\t\tDense(classes,kernel_initializer=\"he_normal\"),\n",
    "\t\t\tSoftmax()])\n",
    "\t\treturn model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_dict = {0:\"Angry\", 1:\"Disgust\", 2:\"Fear\", 3:\"Happy\", 4:\"Sad\", 5:\"Surprise\", 6:\"Neutral\"}\n",
    "BASE_DIR = \"dataset/kaggle_fer/fer2013/\"\n",
    "data = pd.read_csv(BASE_DIR+\"fer2013.csv\")\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28709, 48, 48), (28709,), array([[ 70,  80,  82, ...,  52,  43,  41],\n",
       "        [ 65,  61,  58, ...,  56,  52,  44],\n",
       "        [ 50,  43,  54, ...,  49,  56,  47],\n",
       "        ...,\n",
       "        [ 91,  65,  42, ...,  72,  56,  43],\n",
       "        [ 77,  82,  79, ..., 105,  70,  46],\n",
       "        [ 77,  72,  84, ..., 106, 109,  82]], dtype=uint8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pixels = [np.array([int(i) for i in j.split()]) for j in data[data.Usage == \"Training\"][\"pixels\"].values]\n",
    "train_pixels = np.array([i.reshape((48,48)) for i in train_pixels],dtype=np.uint8)\n",
    "train_labels = np.array([int(j) for j in data[data.Usage == 'Training'][\"emotion\"].values],dtype=np.uint8)\n",
    "train_pixels.shape,train_labels.shape,train_pixels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixels = [np.array([int(i) for i in j.split()]) for j in data[data.Usage == \"PrivateTest\"][\"pixels\"].values]\n",
    "test_pixels = np.array([i.reshape((48,48)) for i in test_pixels])\n",
    "test_labels = np.array([int(j) for j in data[data.Usage == 'PrivateTest'][\"emotion\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_pixels = [np.array([int(i) for i in j.split()]) for j in data[data.Usage == \"PublicTest\"][\"pixels\"].values]\n",
    "validation_pixels = np.array([i.reshape((48,48)) for i in validation_pixels])\n",
    "validation_labels = np.array([int(j) for j in data[data.Usage == 'PublicTest'][\"emotion\"].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rotation_range=10, zoom_range=0.1,horizontal_flip=True, rescale=1 / 255.0, fill_mode=\"nearest\")\n",
    "test = ImageDataGenerator(rescale=1 / 255.0)\n",
    "validation = ImageDataGenerator(rescale=1 / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] compiled\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = EmotionVGGNet.build(width=48, height=48, depth=1,classes=len(emotion_dict))\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "print(\"[INFO] compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (28709, 48, 48))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-455be7a6e642>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.fit_generator(\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_pixels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         )\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             dtype=dtype)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf/lib/python3.6/site-packages/keras_preprocessing/image/numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[1;32m    115\u001b[0m             raise ValueError('Input data in `NumpyArrayIterator` '\n\u001b[1;32m    116\u001b[0m                              \u001b[0;34m'should have rank 4. You passed an array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                              'with shape', self.x.shape)\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mchannels_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_last'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannels_axis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (28709, 48, 48))"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights/EmotionVGGNet.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "#model.fit_generator(\n",
    "#    train.flow_from_dataframe(data,x_col=\n",
    "#)\n",
    "\n",
    "model.fit_generator(\n",
    "\ttrain.flow(train_pixels,train_labels,batch_size=32),\n",
    "\tvalidation_data = validation.flow(validation_pixels,validation_labels),\n",
    "\tepochs = 15,\n",
    "\tcallbacks = [checkpointer],\n",
    "\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EmotionVGGNet.hdf5\")\n",
    "model = load_model(\"EmotionVGGNet.hdf5\")\n",
    "\n",
    "loss, acc = model.evaluate_generatoor(\n",
    "\ttest.flow(test_pixels,test_labels,color_mode=\"grayscale\"))\n",
    "\n",
    "print(\"[INFO] accuracy : {:.2f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
